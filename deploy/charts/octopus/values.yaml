# Default values for octopus.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

tolerations: []
affinity: {}
resources: {}

global:
  image:
    repository:
      address: "swr.cn-south-1.myhuaweicloud.com"
      pathname: "/openioctopus"
    pullPolicy: IfNotPresent
  nodeSelector: &nodeSelector
    octopus.openi.pcl.cn/node: "server"
  affinity: &affinity
    nodeAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        preference:
          matchExpressions:
          - key: kubernetes.io/arch
            operator: In
            values: ["amd64", "x64", "x86-64", "x86_64"]
      - weight: 100
        preference:
          matchExpressions:
          - key: beta.kubernetes.io/arch
            operator: In
            values: ["amd64", "x64", "x86-64", "x86_64"]

common:
  resourceTagKey: octopus.pcl.ac.cn/type
  resourceTagValuePrefix: service

ingress:
  enabled: true
  adminserverPath: /adminserver
  openaiserverPath: /openaiserver
  platformserverPath: /platformserver
  adminportalPath: /admin
  openaiportalPath: /openai
  loggerHttpdPath: /log
  ambassadorPath: /seldon
  minioPath:
    web: /minio
    api: /oss
  apidocPath: /apidoc
  tls: []


pvc:
  minio:
    requests: 100Gi
  mysql:
    requests: 100Gi
  redis:
    requests: 100Gi
  influxdb:
    requests: 100Gi
  logger:
    requests: 100Gi

pv:
  minio:
    requests: 100Gi
    storageType:
      nfs:
        server:  192.168.203.72
        path:  /data/datasets/data/minio
  mysql:
    requests: 100Gi
    storageType:
      nfs:
        server:  192.168.203.72
        path:  /data/datasets/data/mysql
  redis:
    requests: 100Gi
    storageType:
      nfs:
        server:  192.168.203.72
        path:  /data/datasets/data/redis
  influxdb:
    requests: 100Gi
    storageType:
      nfs:
        server:  192.168.203.72
        path:  /data/datasets/data/influxdb
  logger:
    requests: 100Gi
    storageType:
      nfs:
        server:  192.168.203.72
        path:  /data/datasets/data/logger

# taskset
taskset:
  replicaCount: 1
  adminToken: "KLtmMug9BDvvRjlg"
  image:
    pullPolicy: ""
    address: ""
    pathname: ""
    name: "pipeline"

# base-server
baseserver:
  replicas: 1
  image:
    pullPolicy: ""
    address: ""
    pathname: ""
    name: "base-server"
  app:
    logLevel: info
  data:
    minio:
      base:
        accessKeyID: minioadmin
        secretAccessKey: minioadmin
        useSSL: false
        mountPath: /data
    harbor:
      host: 192.168.202.74:5000
      username: openi
      password: OpenI2018
      apiVersion: v1.0
      useSSL: false
    redis:
      username: ""
      password: "abcde"
    jointCloud:  #需要修改为实际的值
      baseUrl: jointCloudBaseUrl
      username: jointCloudUsername
      password: jointCloudPassword
      sessionExpirySec: 540 #实际有效期为600
    ambassador: #需要修改为实际的值
      baseUrl: 192.168.202.73
    pytorchServer:
      imageAddr: 192.168.202.110:5000/octopus/pytorchserver
      version: 2.0.4
  service:
    billingPeriodSec: 1800
    develop:
      jpyCommand: "jupyter lab --no-browser --ip=0.0.0.0 --allow-root --notebook-dir='/code' --port=8888 --LabApp.token='' --LabApp.allow_origin='*' --LabApp.base_url=$OCTOPUS_JPY_BASE_URL"
      autoStopIntervalSec: 7200
  administrator:
    username: "admin"
    password: "123456"
    email: ""
    phone: ""

# openai-server
openaiserver:
  replicas: 1
  image:
    pullPolicy: ""
    address: ""
    pathname: ""
    name: "openai-server"
  app:
    logLevel: info
  server:
    oauth:
      pcl:
        authServerURL: "https://one.pcl.ac.cn/idp/oauth2"
        clientID: "yn1"
        clientSecret: "74d4543ca3d74f42af841479c5c6d045"
        redirectURL: "http://192.168.202.73/openaiserver/v1/oauth2/pcl/callback"
      registerURL: "http://192.168.202.73/openai/"
  data:
    redis:
      username: ""
      password: "abcde"
  service:
    webConfig:
      logoAddr:
      #格式如#94070a
      themeColor:
      systemNameEn:
      systemNameZh:
      organization:
      manualInvisible:
      thirdPlatform: "pcl"

# platform-server
platformserver:
  image:
    pullPolicy: ""
    address: ""
    pathname: ""
    name: "platform-server"
  app:
    logLevel: info
  data:
    redis:
      username: ""
      password: "abcde"

# admin-server
adminserver:
  replicas: 1
  image:
    pullPolicy: ""
    address: ""
    pathname: ""
    name: "admin-server"
  app:
    logLevel: info
  data:
    redis:
      username: ""
      password: "abcde"

# openaiportal
openaiportal:
  replicas: 1
  image:
    pullPolicy: ""
    address: ""
    pathname: ""
    name: "openai-portal"


# adminportal
adminportal:
  replicas: 1
  image:
    pullPolicy: ""
    address: ""
    pathname: ""
    name: "admin-portal"


# scheduler
scheduler:
  replicaCount: 1
  image:
    name: "scheduler"
    

# controller
controller:
  replicaCount: 1
  image:
    name: "vc-controller"

# logger
logger:
  filebeat:
    resources: {}
  logstash:
    nodeSelector:
      <<: *nodeSelector
  httpd:
    replicaCount: 1
    image:
      pullPolicy: Always
    nodeSelector:
      <<: *nodeSelector


# minio
minio:
  podSecurityContext:
    fsGroup: 0
  containerSecurityContext:
    runAsNonRoot: false
    runAsUser: 0
  gateway:
    enabled: true
    type: nas
    replicaCount: 1
    auth:
      nas:
        accessKey: "minioadmin"
        secretKey: "minioadmin"
  persistence:
    size: "100Gi"
    existingClaim: "octopus-minio-pvc"
  service:
    type: NodePort
    nodePort: "31311"
    port: "9000"
  nodeSelector:
    <<: *nodeSelector
  affinity:
    <<: *affinity


# mysql
mysql:
  auth:
    rootPassword: "root"
  volumePermissions:
    enabled: true
  primary:
    service:
      type: NodePort
      port: "3306"
      nodePort: "30336"
    persistence:
      enabled: true
      size: "100Gi"
      existingClaim: "octopus-mysql-pvc"
    extraVolumeMounts:
      - name: mysql-initdb
        mountPath: /docker-entrypoint-initdb.d
    extraVolumes:
      - name: mysql-initdb
        configMap:
          name: mysql-initdb-config
    nodeSelector:
      <<: *nodeSelector
    affinity:
      <<: *affinity


# redis
redis:
  architecture: standalone
  master:
    service:
      type: NodePort
      port: "6379"
    persistence:
      size: "50Gi"
      existingClaim: "octopus-redis-pvc"
    nodeSelector:
      <<: *nodeSelector
    affinity:
      <<: *affinity
  auth:
    enabled: true
    password: "abcde"
  volumePermissions:
    enabled: true

# nginx-ingress-controller
nginx-ingress-controller:
  hostNetwork: true
  updateStrategy:
    type: "Recreate"
  replicaCount: 1
  nodeSelector:
    nginx-ingress: "yes"
  affinity:
    <<: *affinity
  defaultBackend:
    affinity:
      <<: *affinity

# influxdb
influxdb:
  replicaCount: 1
  livenessProbe:
    initialDelaySeconds: 300
  readinessProbe:
    initialDelaySeconds: 300
  config:
    data:
      max-series-per-database: 0
      max-values-per-tag: 0
  setDefaultUser:
    user:
      username: "octopus"
      password: "octopus"
  persistence:
    enabled: true
    existingClaim: "octopus-influxdb-pvc"
  volumes:
  - name: influxdb-initdb
    configMap:
      name: influxdb-initdb-config
  mountPoints:
  - name: influxdb-initdb
    mountPath: /docker-entrypoint-initdb.d
    readOnly: true
  nodeSelector:
    <<: *nodeSelector
  affinity:
    <<: *affinity


# grafana
grafana:
  nameOverride: "grafana"
  replicaCount: 1
  image:
    tag: "6.2.0"
  env:
    GF_AUTH_BASIC_ENABLED: "true"
    GF_AUTH_ANONYMOUS_ENABLED: "true"
    GF_AUTH_ANONYMOUS_ORG_ROLE: Viewer
    GF_SECURITY_ADMIN_USER: "admin"
    GF_SECURITY_ADMIN_PASSWORD: "Pa22word"
    GF_SECURITY_ALLOW_EMBEDDING: "true"
    GF_SERVER_ROOT_URL: "/grafana"
  prometheus:
    port: "9090"
  service:
    type: ClusterIP
    port: "3000"
    targetPort: "3000"
  ingress:
    enabled: true
    annotations: {}
    path: /grafana
  resources: {}
  affinity: {}
  nodeSelector:
    <<: *nodeSelector

#prometheus
prometheus:
  nameOverride: "prometheus"
  replicaCount: 1
  retentionDuration: 365d
  volumes:
    dataPath: /applications/prometheus
  image:
    tag: "2.28.1"
  service:
    type: NodePort
    hostPort: "30003"
    port: "9090"
    targetPort: "9090"
  resources: {}
  affinity: {}
  nodeSelector:
    <<: *nodeSelector

# apidoc
apidoc:
  image:
    pullPolicy: ""
    address: ""
    pathname: ""
    name: "api-doc"

nodeagent:
  image:
    pullPolicy: ""
    address: ""
    pathname: ""
    name: "node-agent"
  resources: {}
  nodeSelector: {}

# seldon-core-operator
seldon-core-operator:
  ambassador:
    enabled: true
  usageMetrics:
    enabled: true
  namespaceOverride: seldon-system
  predictor_servers:
    PYTORCH_SERVER:
      protocols:
        seldon:
          defaultImageVersion: "2.0.4"
          image: "192.168.202.110:5000/octopus/pytorchserver"